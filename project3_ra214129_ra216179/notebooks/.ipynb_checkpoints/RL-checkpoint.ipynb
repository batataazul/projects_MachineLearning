{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gabriel/Documentos/Tarefas/Universidade/MC886/projects_MachineLearning/project3_ra214129_ra216179/search/search\n"
     ]
    }
   ],
   "source": [
    "%cd ../search/search\n",
    "#! python pacman.py --layout originalClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pacman import runGames, readCommand\n",
    "from game import Agent, Directions\n",
    "from util import manhattanDistance\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getState(state):\n",
    "    currentState = (state.getPacmanPosition(),Qlearn.getNearestFoodDis(state),state.getNumFood() + len(state.getCapsules()),Qlearn.nearestGhostPos(state))\n",
    "    return currentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearn(Agent):\n",
    "    def __init__(self, alpha,gamma,epsilon = 1,Qtable = {}):\n",
    "        self.Qtable = Qtable\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.score = 0\n",
    "        self.action = None\n",
    "        self.currentState = None\n",
    "        self.actions = []\n",
    "        self.currentActions = 0\n",
    "        self.rewards = []\n",
    "        self.reward = 0\n",
    "        self.scores = []\n",
    "    \n",
    "    def getQvalue(self,state,action):\n",
    "        pair = str((state,action))\n",
    "        return self.Qtable.get(pair,0.0)\n",
    "    \n",
    "    def getAction(self, state):\n",
    "        actions = state.getLegalPacmanActions()\n",
    "        self.score = state.getScore()\n",
    "        currentState = getState(state)\n",
    "        action = self.getBestAction(currentState,actions)\n",
    "        state2 = state.generatePacmanSuccessor(action)\n",
    "        nextState = getState(state2)\n",
    "        if state2.isLose():\n",
    "            reinforcement = -20000\n",
    "        elif state2.isWin():\n",
    "            reinforcement = 20000\n",
    "        else:\n",
    "            reinforcement = self.getReward(currentState,nextState,state2.getScore())\n",
    "        self.learn(currentState,nextState,action,actions,reinforcement)\n",
    "        self.action = action\n",
    "        self.currentState = currentState\n",
    "        self.currentActions += 1\n",
    "        self.reward += reinforcement\n",
    "        return action\n",
    "        \n",
    "        \n",
    "    def nearestGhostPos(state):\n",
    "        ghostList = state.getGhostPositions()\n",
    "        nearestDistance = Qlearn.getNearGhost(state.getPacmanPosition(),ghostList)\n",
    "        return nearestDistance\n",
    "\n",
    "    def getNearGhost(pacman,ghosts):\n",
    "        minDis = float(\"inf\")\n",
    "        minPos = -1\n",
    "        for i in range(len(ghosts)):\n",
    "            distance = manhattanDistance(pacman,ghosts[i])\n",
    "            if distance < minDis:\n",
    "                minDis = distance\n",
    "                minPos = i\n",
    "        if minPos > -1:\n",
    "            return ghosts[minPos]\n",
    "        else:\n",
    "            return (-1,-1)\n",
    "\n",
    "    def getNearestFoodDis(state):\n",
    "        posList = Qlearn.getFoodPos(state.getFood())\n",
    "        posList = posList + state.getCapsules()\n",
    "        minDis = minDis = float(\"inf\")\n",
    "        #minPos = (-1,-1)\n",
    "        pacPos = state.getPacmanPosition()\n",
    "        for i in posList:\n",
    "            distance = manhattanDistance(pacPos,i)\n",
    "            if distance < minDis:\n",
    "                minDis = distance\n",
    "                #minPos = i\n",
    "        return minDis\n",
    "\n",
    "\n",
    "    def getFoodPos(grid):\n",
    "        posList = []\n",
    "        gridList = grid.asList()\n",
    "        for i in range(len(gridList)):\n",
    "            for j in range(len(gridList[i])):\n",
    "                if gridList[i][j]:\n",
    "                    posList.append((i,j))\n",
    "        return posList\n",
    "\n",
    "    def getBestAction(self,currentState,actions):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(actions)\n",
    "        maxValue = float(\"-inf\")\n",
    "        maxAction = []\n",
    "        for i in actions:\n",
    "            value = self.getQvalue(currentState,i)\n",
    "            if value > maxValue:\n",
    "                maxValue = value\n",
    "                maxAction = [i]\n",
    "            if value == maxValue:\n",
    "                maxAction.append(i)\n",
    "        #print(maxValue)\n",
    "        #print(maxAction)\n",
    "        return random.choice(maxAction)\n",
    "\n",
    "    def learn(self,currentState,nextState,action,actions,reinforcement):\n",
    "        nextActions = [self.getQvalue(nextState,a) for a in actions]\n",
    "        if len(nextActions) > 0:\n",
    "            newQ = max(nextActions)\n",
    "        else:\n",
    "            newQ = 0\n",
    "        currentQ = self.getQvalue(currentState,action)\n",
    "        self.Qtable[str((currentState,action))] = currentQ + self.alpha * (reinforcement + (self.gamma*newQ) - currentQ)\n",
    "\n",
    "    def setEpsilon(self,epsilon):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def serialize(self,path):\n",
    "        try:\n",
    "            f = open(path,\"w\")\n",
    "            json.dump(self.Qtable,f)\n",
    "            f.close()\n",
    "        except:\n",
    "            raise Exception(\"You've got an error\")\n",
    "\n",
    "    def desserialize(self,path):\n",
    "        try:\n",
    "            f = open(path,\"r\")\n",
    "            self.Qtable = json.load(f)\n",
    "            f.close()\n",
    "        except:\n",
    "            raise Exception(\"You've got an error\")\n",
    "    \n",
    "    def getReward(self,state1,state2,score):\n",
    "        pacGhostDistance1 = manhattanDistance(state1[0],state1[3])\n",
    "        pacGhostDistance2 = manhattanDistance(state2[0],state2[3])\n",
    "        #fDis1 = manhattanDistance(state1[0],state1[1])\n",
    "        #fDis2 = manhattanDistance(state2[0],state2[1])\n",
    "        eatenFood = state2[2] - state1[2]\n",
    "        ghostDistance = pacGhostDistance2 - pacGhostDistance1\n",
    "        foodDistance = state2[1] - state1[1]\n",
    "        scoreDifference = score - self.score\n",
    "        if ghostDistance > 0:\n",
    "            ghostReward = ghostDistance*200\n",
    "        else:\n",
    "            ghostReward = 200*ghostDistance\n",
    "        if foodDistance < 0:\n",
    "            foodReward = -500 * foodDistance\n",
    "        else:\n",
    "            foodReward = 0\n",
    "        if eatenFood > 0:\n",
    "            eatReward = 500*eatenFood\n",
    "        else:\n",
    "            eatReward = 0\n",
    "        if scoreDifference > 0:\n",
    "            scoreReward = 3*scoreDifference\n",
    "        else:\n",
    "            scoreReward = 5*scoreDifference\n",
    "        return ghostReward + foodReward + eatReward + scoreReward\n",
    "    \n",
    "    def win(self,terminal):\n",
    "        self.saveResult(terminal.state.getScore())\n",
    "        self.learn(self.currentState,getState(terminal.state),self.action,terminal.state.getLegalPacmanActions(),20000)\n",
    "    \n",
    "    def lose(self,terminal):\n",
    "        self.saveResult(terminal.state.getScore())\n",
    "        self.learn(self.currentState,getState(terminal.state),self.action,terminal.state.getLegalPacmanActions(),-20000)\n",
    "    \n",
    "    def saveResult(self, score):\n",
    "        self.actions.append(self.currentActions)\n",
    "        self.scores.append(score)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.currentActions = 0\n",
    "        self.reward = 0\n",
    "        self.score = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best:  \n",
    "GhostReward = 200/200  \n",
    "FoodReward = -500/0  \n",
    "EatReward = 500/0  \n",
    "ScoreReward = 3/5  \n",
    "Alpha = 0.85  \n",
    "Gamma = 0.5  \n",
    "\n",
    "First Win: 3142  \n",
    "Total win: 74  \n",
    "Average: -344.1665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(agente,k):\n",
    "    for i in range(0,k-1,1000):\n",
    "        try:    \n",
    "            print(\"Episode \"+str(i+1)+\": Number of actions = \"+str(agente.actions[i])+\"; Total score = \"+str(agente.scores[i])+\"; Total Reward = \"+str(agente.rewards[i]))\n",
    "        except(IndexError):\n",
    "            print(\"Index out of range\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-q', '--pacman', 'LeftTurnAgent', '--layout', 'smallClassic']\n"
     ]
    }
   ],
   "source": [
    "args = readCommand([\"-q\", \"--pacman\", \"LeftTurnAgent\",\"--layout\",\"smallClassic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agente = Qlearn(0.85,0.5,epsilon = 1)\n",
    "args[\"pacman\"] = agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacman emerges victorious! Score: 894\n",
      "9837\n",
      "Pacman emerges victorious! Score: 664\n",
      "10568\n",
      "Pacman emerges victorious! Score: 504\n",
      "12007\n",
      "Pacman emerges victorious! Score: 819\n",
      "14203\n",
      "Pacman emerges victorious! Score: 975\n",
      "16488\n",
      "Pacman emerges victorious! Score: 391\n",
      "17035\n",
      "Pacman emerges victorious! Score: 796\n",
      "17179\n",
      "Pacman emerges victorious! Score: 1077\n",
      "17222\n",
      "Pacman emerges victorious! Score: 833\n",
      "17912\n",
      "Pacman emerges victorious! Score: 896\n",
      "17976\n",
      "Pacman emerges victorious! Score: 735\n",
      "18216\n",
      "Pacman emerges victorious! Score: 854\n",
      "18587\n",
      "Pacman emerges victorious! Score: 537\n",
      "21790\n",
      "Pacman emerges victorious! Score: 488\n",
      "22541\n",
      "Pacman emerges victorious! Score: 780\n",
      "22716\n",
      "Pacman emerges victorious! Score: 635\n",
      "23691\n",
      "Pacman emerges victorious! Score: 808\n",
      "23761\n",
      "Pacman emerges victorious! Score: 842\n",
      "23807\n",
      "Pacman emerges victorious! Score: 409\n",
      "23850\n",
      "Pacman emerges victorious! Score: 470\n",
      "24179\n",
      "Pacman emerges victorious! Score: 698\n",
      "24452\n",
      "Pacman emerges victorious! Score: 988\n",
      "24777\n",
      "Pacman emerges victorious! Score: 650\n",
      "25226\n",
      "Pacman emerges victorious! Score: 786\n",
      "25666\n",
      "Pacman emerges victorious! Score: 729\n",
      "25842\n",
      "Pacman emerges victorious! Score: 833\n",
      "25941\n",
      "Pacman emerges victorious! Score: 689\n",
      "26518\n",
      "Pacman emerges victorious! Score: 635\n",
      "26537\n",
      "Pacman emerges victorious! Score: 567\n",
      "27064\n",
      "Pacman emerges victorious! Score: 782\n",
      "27566\n",
      "Pacman emerges victorious! Score: 809\n",
      "27723\n",
      "Pacman emerges victorious! Score: 779\n",
      "28132\n",
      "Pacman emerges victorious! Score: 735\n",
      "28307\n",
      "Pacman emerges victorious! Score: 713\n",
      "28355\n",
      "Pacman emerges victorious! Score: 352\n",
      "28358\n",
      "Pacman emerges victorious! Score: 992\n",
      "28386\n",
      "Pacman emerges victorious! Score: 780\n",
      "28484\n",
      "Pacman emerges victorious! Score: 786\n",
      "29146\n",
      "Pacman emerges victorious! Score: 646\n",
      "29895\n",
      "Pacman emerges victorious! Score: 994\n",
      "30026\n",
      "Pacman emerges victorious! Score: 737\n",
      "31191\n",
      "Pacman emerges victorious! Score: 1076\n",
      "31627\n",
      "Pacman emerges victorious! Score: 737\n",
      "31629\n",
      "Pacman emerges victorious! Score: 971\n",
      "31637\n",
      "Pacman emerges victorious! Score: 745\n",
      "31666\n",
      "Pacman emerges victorious! Score: 748\n",
      "31740\n",
      "Pacman emerges victorious! Score: 342\n",
      "31859\n",
      "Pacman emerges victorious! Score: 989\n",
      "32157\n",
      "Pacman emerges victorious! Score: 511\n",
      "32304\n",
      "Pacman emerges victorious! Score: 1004\n",
      "32667\n",
      "Pacman emerges victorious! Score: 715\n",
      "33028\n",
      "Pacman emerges victorious! Score: 488\n",
      "33196\n",
      "Pacman emerges victorious! Score: 666\n",
      "33257\n",
      "Pacman emerges victorious! Score: 540\n",
      "33477\n",
      "Pacman emerges victorious! Score: 435\n",
      "33493\n",
      "Pacman emerges victorious! Score: 466\n",
      "33499\n",
      "Pacman emerges victorious! Score: 687\n",
      "34358\n",
      "Pacman emerges victorious! Score: 664\n",
      "34685\n",
      "Pacman emerges victorious! Score: 708\n",
      "34783\n",
      "Pacman emerges victorious! Score: 607\n",
      "35369\n",
      "Pacman emerges victorious! Score: 902\n",
      "35933\n",
      "Pacman emerges victorious! Score: 533\n",
      "36032\n",
      "Pacman emerges victorious! Score: 822\n",
      "36194\n",
      "Pacman emerges victorious! Score: 593\n",
      "36358\n",
      "Pacman emerges victorious! Score: 996\n",
      "36360\n",
      "Pacman emerges victorious! Score: 849\n",
      "36551\n",
      "Pacman emerges victorious! Score: 669\n",
      "36555\n",
      "Pacman emerges victorious! Score: 795\n",
      "36588\n",
      "Pacman emerges victorious! Score: 819\n",
      "36712\n",
      "Pacman emerges victorious! Score: 464\n",
      "36723\n",
      "Pacman emerges victorious! Score: 364\n",
      "36788\n",
      "Pacman emerges victorious! Score: 430\n",
      "36833\n",
      "Pacman emerges victorious! Score: 674\n",
      "37600\n",
      "Pacman emerges victorious! Score: 982\n",
      "37711\n",
      "Pacman emerges victorious! Score: 875\n",
      "38048\n",
      "Pacman emerges victorious! Score: 1084\n",
      "38129\n",
      "Pacman emerges victorious! Score: 563\n",
      "38167\n",
      "Pacman emerges victorious! Score: 716\n",
      "38408\n",
      "Pacman emerges victorious! Score: 624\n",
      "38461\n",
      "Pacman emerges victorious! Score: 469\n",
      "38611\n",
      "Pacman emerges victorious! Score: 650\n",
      "38906\n",
      "Pacman emerges victorious! Score: 917\n",
      "39152\n",
      "Pacman emerges victorious! Score: 672\n",
      "39252\n",
      "Pacman emerges victorious! Score: 493\n",
      "39470\n"
     ]
    }
   ],
   "source": [
    "victorys = []\n",
    "k = 40000\n",
    "summ = 0\n",
    "for i in range(k):\n",
    "    agente.setEpsilon(1/(i+1))\n",
    "    a.append(runGames(**args))\n",
    "    if a[i][0].state.isLose():\n",
    "        agente.lose(a[i][0])\n",
    "    elif a[i][0].state.isWin():\n",
    "        agente.win(a[i][0])\n",
    "        victorys.append(a[i])\n",
    "        print(i)\n",
    "    summ += a[i][0].state.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Number of actions = 63; Total score = -483.0; Total Reward = 541.0\n",
      "Episode 1001: Number of actions = 85; Total score = -415.0; Total Reward = 13219.0\n",
      "Episode 2001: Number of actions = 256; Total score = -506.0; Total Reward = 48520.0\n",
      "Episode 3001: Number of actions = 145; Total score = -425.0; Total Reward = -6016.0\n",
      "Episode 4001: Number of actions = 168; Total score = -288.0; Total Reward = 33076.0\n",
      "Episode 5001: Number of actions = 34; Total score = -434.0; Total Reward = 2950.0\n",
      "Episode 6001: Number of actions = 98; Total score = -438.0; Total Reward = 13822.0\n",
      "Episode 7001: Number of actions = 179; Total score = -249.0; Total Reward = 39081.0\n",
      "Episode 8001: Number of actions = 47; Total score = -417.0; Total Reward = 7781.0\n",
      "Episode 9001: Number of actions = 58; Total score = -298.0; Total Reward = 9942.0\n",
      "Episode 10001: Number of actions = 168; Total score = -248.0; Total Reward = 35204.0\n",
      "Episode 11001: Number of actions = 309; Total score = -319.0; Total Reward = 31590.0\n",
      "Episode 12001: Number of actions = 41; Total score = -151.0; Total Reward = 9905.0\n",
      "Episode 13001: Number of actions = 164; Total score = -224.0; Total Reward = 25450.0\n",
      "Episode 14001: Number of actions = 82; Total score = -322.0; Total Reward = 13422.0\n",
      "Episode 15001: Number of actions = 41; Total score = -391.0; Total Reward = 7275.0\n",
      "Episode 16001: Number of actions = 81; Total score = -391.0; Total Reward = 20603.0\n",
      "Episode 17001: Number of actions = 105; Total score = -255.0; Total Reward = 19895.0\n",
      "Episode 18001: Number of actions = 111; Total score = -231.0; Total Reward = 20361.0\n",
      "Episode 19001: Number of actions = 231; Total score = -381.0; Total Reward = 8370.0\n",
      "Episode 20001: Number of actions = 19; Total score = -429.0; Total Reward = 1993.0\n",
      "Episode 21001: Number of actions = 376; Total score = -166.0; Total Reward = 42457.0\n",
      "Episode 22001: Number of actions = 175; Total score = -315.0; Total Reward = 32677.0\n",
      "Episode 23001: Number of actions = 40; Total score = -430.0; Total Reward = 3852.0\n",
      "Episode 24001: Number of actions = 124; Total score = -134.0; Total Reward = 4215.0\n",
      "Episode 25001: Number of actions = 155; Total score = -305.0; Total Reward = 19345.0\n",
      "Episode 26001: Number of actions = 182; Total score = -472.0; Total Reward = 23662.0\n",
      "Episode 27001: Number of actions = 79; Total score = -439.0; Total Reward = -15174.0\n",
      "Episode 28001: Number of actions = 80; Total score = -220.0; Total Reward = 16452.0\n",
      "Episode 29001: Number of actions = 419; Total score = -189.0; Total Reward = 78603.0\n",
      "Episode 30001: Number of actions = 107; Total score = -367.0; Total Reward = 12133.0\n",
      "Episode 31001: Number of actions = 144; Total score = -444.0; Total Reward = -575.0\n",
      "Episode 32001: Number of actions = 86; Total score = -396.0; Total Reward = 16078.0\n",
      "Episode 33001: Number of actions = 158; Total score = -268.0; Total Reward = 30620.0\n",
      "Episode 34001: Number of actions = 243; Total score = 27.0; Total Reward = 45673.0\n",
      "Episode 35001: Number of actions = 221; Total score = -81.0; Total Reward = 39405.0\n",
      "Episode 36001: Number of actions = 33; Total score = -363.0; Total Reward = 5979.0\n",
      "Episode 37001: Number of actions = 53; Total score = -163.0; Total Reward = 10645.0\n",
      "Episode 38001: Number of actions = 185; Total score = -225.0; Total Reward = 36947.0\n",
      "Episode 39001: Number of actions = 173; Total score = -43.0; Total Reward = 7418.0\n"
     ]
    }
   ],
   "source": [
    "showResults(agente,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agente.serialize(\"../../notebooks/results/small/a085-g03-d100721-2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "-343.3107\n"
     ]
    }
   ],
   "source": [
    "print(len(victorys))\n",
    "print(summ/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-q', '--pacman', 'LeftTurnAgent', '--layout', 'mediumClassic']\n"
     ]
    }
   ],
   "source": [
    "argsM = readCommand([\"-q\", \"--pacman\", \"LeftTurnAgent\",\"--layout\",\"mediumClassic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aM = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenteM = Qlearn(0.85,0.3,epsilon = 1)\n",
    "argsM[\"pacman\"] = agenteM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victorysM = []\n",
    "kM = 80000\n",
    "summM = 0\n",
    "for i in range(kM):\n",
    "    agenteM.setEpsilon(1/(i+1))\n",
    "    aM.append(runGames(**argsM))\n",
    "    if aM[i][0].state.isLose():\n",
    "        agenteM.lose(aM[i][0])\n",
    "    elif aM[i][0].state.isWin():\n",
    "        agenteM.win(aM[i][0])\n",
    "        victorysM.append(aM[i])\n",
    "        print(i)\n",
    "    summM += aM[i][0].state.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenteM.serialize(\"../../notebooks/results/medium/a085-g03-d090721.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(victorysM))\n",
    "print(summM/kO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsO = readCommand([\"-q\", \"--pacman\", \"LeftTurnAgent\",\"--layout\",\"originalClassic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aO = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenteO = Qlearn(0.85,0.3,epsilon = 1)\n",
    "argsO[\"pacman\"] = agenteO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victorysO = []\n",
    "kO = 120000\n",
    "summO = 0\n",
    "for i in range(kO):\n",
    "    agenteO.setEpsilon(1/(i+1))\n",
    "    aO.append(runGames(**argsO))\n",
    "    if aO[i][0].state.isLose():\n",
    "        agenteO.lose(aO[i][0])\n",
    "    elif aO[i][0].state.isWin():\n",
    "        agenteO.win(aO[i][0])\n",
    "        victorysO.append(aO[i])\n",
    "        print(i)\n",
    "    summ0 += aO[i][0].state.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenteO.serialize(\"../../notebooks/results/original/a085-g03-d090721.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(victorysO))\n",
    "print(summO/kO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smartPacman(Agent):\n",
    "    def __init__(self, path):\n",
    "        self.desserialize(path)\n",
    "        self.score = 0\n",
    "        self.action = 0\n",
    "    \n",
    "    def getQvalue(self,state,action):\n",
    "        pair = str((state,action))\n",
    "        return self.Qtable.get(pair,0.0)\n",
    "    \n",
    "    def getAction(self, state):\n",
    "        actions = state.getLegalPacmanActions()\n",
    "        currentState = getState(state)\n",
    "        action = self.getBestAction(currentState,actions)\n",
    "        return action\n",
    "    \n",
    "    def getBestAction(self,currentState,actions):\n",
    "        maxValue = float(\"-inf\")\n",
    "        maxAction = []\n",
    "        for i in actions:\n",
    "            value = self.getQvalue(currentState,i)\n",
    "            if value > maxValue:\n",
    "                maxValue = value\n",
    "                maxAction = [i]\n",
    "            if value == maxValue:\n",
    "                maxAction.append(i)\n",
    "        #print(maxValue)\n",
    "        #print(maxAction)\n",
    "        self.action += 1\n",
    "        return random.choice(maxAction)\n",
    "    \n",
    "    def desserialize(self,path):\n",
    "        try:\n",
    "            f = open(path,\"r\")\n",
    "            self.Qtable = json.load(f)\n",
    "            f.close()\n",
    "        except:\n",
    "            raise Exception(\"You've got an error\")\n",
    "    def finish(self,state):\n",
    "        self.score = state.getScore()\n",
    "        self.action = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--pacman', 'LeftTurnAgent', '--layout', 'smallClassic']\n"
     ]
    }
   ],
   "source": [
    "#agenteEsperto = smartPacman(\".../../notebooks/results/small/a085-g03-d100721.json\")\n",
    "agenteEsperto = smartPacman(\"../../notebooks/results/small/a085-g03-d100721.json\")\n",
    "argsV = readCommand([\"--pacman\", \"LeftTurnAgent\",\"--layout\",\"smallClassic\"])\n",
    "argsV[\"pacman\"] = agenteEsperto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "-284.0\n"
     ]
    }
   ],
   "source": [
    "a = runGames(**argsV)\n",
    "print(a[0].state.isWin())\n",
    "print(a[0].state.getScore())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a33e6643d3d266930a9315102c951dbbb0201b743375bf7e85bc0f4d5308486"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
