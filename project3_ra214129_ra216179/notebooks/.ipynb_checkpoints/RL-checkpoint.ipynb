{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel de Freitas\\OneDrive\\Documentos\\Tarefas\\Universidade\\MC886\\projects_MachineLearning\\project3_ra214129_ra216179\\search\\search\n"
     ]
    }
   ],
   "source": [
    "%cd ../search/search\n",
    "#! python pacman.py --layout originalClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pacman import runGames, readCommand\n",
    "from game import Agent, Directions\n",
    "from util import manhattanDistance\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getState(state):\n",
    "    currentState = (state.getPacmanPosition(),Qlearn.getNearestFoodDis(state),state.getNumFood() + len(state.getCapsules()),Qlearn.nearestGhostPos(state))\n",
    "    return currentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearn(Agent):\n",
    "    def __init__(self, alpha,gamma,epsilon = 1,Qtable = {}):\n",
    "        self.Qtable = Qtable\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.score = 0\n",
    "        self.action = None\n",
    "        self.currentState = None\n",
    "    \n",
    "    def getQvalue(self,state,action):\n",
    "        pair = str((state,action))\n",
    "        return self.Qtable.get(pair,0.0)\n",
    "    \n",
    "    def getAction(self, state):\n",
    "        actions = state.getLegalPacmanActions()\n",
    "        currentState = getState(state)\n",
    "        action = self.getBestAction(currentState,actions)\n",
    "        state2 = state.generatePacmanSuccessor(action)\n",
    "        nextState = getState(state2)\n",
    "        if state2.isLose():\n",
    "            reinforcement = -20000\n",
    "        elif state2.isWin():\n",
    "            reinforcement = 20000\n",
    "        else:\n",
    "            reinforcement = self.getReward(currentState,nextState,state2.getScore())\n",
    "        self.learn(currentState,nextState,action,actions,reinforcement)\n",
    "        self.action = action\n",
    "        self.currentState = currentState\n",
    "        return action\n",
    "        \n",
    "        \n",
    "    def nearestGhostPos(state):\n",
    "        ghostList = state.getGhostPositions()\n",
    "        nearestDistance = Qlearn.getNearGhost(state.getPacmanPosition(),ghostList)\n",
    "        return nearestDistance\n",
    "\n",
    "    def getNearGhost(pacman,ghosts):\n",
    "        minDis = float(\"inf\")\n",
    "        minPos = -1\n",
    "        for i in range(len(ghosts)):\n",
    "            distance = manhattanDistance(pacman,ghosts[i])\n",
    "            if distance < minDis:\n",
    "                minDis = distance\n",
    "                minPos = i\n",
    "        if minPos > -1:\n",
    "            return ghosts[minPos]\n",
    "        else:\n",
    "            return (-1,-1)\n",
    "\n",
    "    def getNearestFoodDis(state):\n",
    "        posList = Qlearn.getFoodPos(state.getFood())\n",
    "        posList = posList + state.getCapsules()\n",
    "        minDis = minDis = float(\"inf\")\n",
    "        pacPos = state.getPacmanPosition()\n",
    "        for i in posList:\n",
    "            distance = manhattanDistance(pacPos,i)\n",
    "            if distance < minDis:\n",
    "                minDis = distance\n",
    "        return minDis\n",
    "\n",
    "\n",
    "    def getFoodPos(grid):\n",
    "        posList = []\n",
    "        gridList = grid.asList()\n",
    "        for i in range(len(gridList)):\n",
    "            for j in range(len(gridList[i])):\n",
    "                if gridList[i][j]:\n",
    "                    posList.append((i,j))\n",
    "        return posList\n",
    "\n",
    "    def getBestAction(self,currentState,actions):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(actions)\n",
    "        maxValue = float(\"-inf\")\n",
    "        maxAction = []\n",
    "        for i in actions:\n",
    "            value = self.getQvalue(currentState,i)\n",
    "            if value > maxValue:\n",
    "                maxValue = value\n",
    "                maxAction = [i]\n",
    "            if value == maxValue:\n",
    "                maxAction.append(i)\n",
    "        #print(maxValue)\n",
    "        #print(maxAction)\n",
    "        return random.choice(maxAction)\n",
    "\n",
    "    def learn(self,currentState,nextState,action,actions,reinforcement):\n",
    "        nextActions = [self.getQvalue(nextState,a) for a in actions]\n",
    "        if len(nextActions) > 0:\n",
    "            newQ = max(nextActions)\n",
    "        else:\n",
    "            newQ = 0\n",
    "        currentQ = self.getQvalue(currentState,action)\n",
    "        self.Qtable[str((currentState,action))] = currentQ + self.alpha * (reinforcement + (self.gamma*newQ) - currentQ)\n",
    "\n",
    "    def setEpsilon(self,epsilon):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def serialize(self,path):\n",
    "        try:\n",
    "            f = open(path,\"w\")\n",
    "            json.dump(self.Qtable,f)\n",
    "            f.close()\n",
    "        except:\n",
    "            raise Exception(\"You've got an error\")\n",
    "\n",
    "    def desserialize(self,path):\n",
    "        try:\n",
    "            f = open(path,\"r\")\n",
    "            self.Qtable = json.load(f)\n",
    "            f.close()\n",
    "        except:\n",
    "            raise Exception(\"You've got an error\")\n",
    "    \n",
    "    def getReward(self,state1,state2,score):\n",
    "        pacGhostDistance1 = manhattanDistance(state1[0],state1[3])\n",
    "        pacGhostDistance2 = manhattanDistance(state2[0],state2[3])\n",
    "        eatenFood = state2[2] - state1[2]\n",
    "        ghostDistance = pacGhostDistance2 - pacGhostDistance1\n",
    "        foodDistance = state2[1] - state1[1]\n",
    "        if ghostDistance > 0:\n",
    "            ghostReward = ghostDistance*150\n",
    "        else:\n",
    "            ghostReward = 75*ghostDistance\n",
    "        if foodDistance < 0:\n",
    "            foodReward = -200 * foodDistance\n",
    "        else:\n",
    "            foodReward = 0\n",
    "        if eatenFood > 0:\n",
    "            eatReward = 300*eatenFood\n",
    "        else:\n",
    "            eatReward = 0\n",
    "        scoreReward = 0.6*(score - self.score)\n",
    "        return ghostReward + foodReward + eatReward + scoreReward\n",
    "    \n",
    "    def win(self,terminal):\n",
    "        self.learn(self.currentState,getState(terminal.state),self.action,terminal.state.getLegalPacmanActions(),20000)\n",
    "    \n",
    "    def lose(self,terminal):\n",
    "        self.learn(self.currentState,getState(terminal.state),self.action,terminal.state.getLegalPacmanActions(),-20000)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-q', '--pacman', 'LeftTurnAgent', '--layout', 'smallClassic']\n"
     ]
    }
   ],
   "source": [
    "agente = Qlearn(0.75,0.4,epsilon = 1)\n",
    "args = readCommand([\"-q\", \"--pacman\", \"LeftTurnAgent\",\"--layout\",\"smallClassic\"])\n",
    "args[\"pacman\"] = agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<game.Game object at 0x000001EDDAF3A2C8>]\n"
     ]
    }
   ],
   "source": [
    "a = runGames(**args)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-q', '--pacman', 'LeftTurnAgent', '--layout', 'smallClassic']\n"
     ]
    }
   ],
   "source": [
    "args = readCommand([\"-q\", \"--pacman\", \"LeftTurnAgent\",\"--layout\",\"smallClassic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "agente = Qlearn(0.75,0.25,epsilon = 1)\n",
    "args[\"pacman\"] = agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacman emerges victorious! Score: 620\n",
      "9618\n",
      "Pacman emerges victorious! Score: 660\n",
      "15341\n",
      "Pacman emerges victorious! Score: 527\n",
      "18162\n"
     ]
    }
   ],
   "source": [
    "victorys = []\n",
    "for i in range(20000):\n",
    "    agente.setEpsilon(1/(i+1))\n",
    "    a.append(runGames(**args))\n",
    "    if a[i][0].state.isLose():\n",
    "        agente.lose(a[i][0])\n",
    "    elif a[i][0].state.isWin():\n",
    "        agente.win(a[i][0])\n",
    "        victorys.append(a[i])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "-698.0\n"
     ]
    }
   ],
   "source": [
    "print(a[len(a)-1][0].state.isWin())\n",
    "print(a[len(a)-1][0].state.getScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agente.serialize(\"../../notebooks/results/a075-g05-d040721.json\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a33e6643d3d266930a9315102c951dbbb0201b743375bf7e85bc0f4d5308486"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
