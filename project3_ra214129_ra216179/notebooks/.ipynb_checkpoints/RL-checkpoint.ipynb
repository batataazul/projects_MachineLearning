{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel de Freitas\\OneDrive\\Documentos\\Tarefas\\Universidade\\MC886\\projects_MachineLearning\\project3_ra214129_ra216179\\search\\search\n"
     ]
    }
   ],
   "source": [
    "%cd ../search/search\n",
    "#! python pacman.py --layout originalClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pacman import runGames, readCommand\n",
    "from game import Agent, Directions\n",
    "from util import manhattanDistance\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getState(state):\n",
    "    currentState = (state.getPacmanPosition(),Qlearn.getNearestFoodDis(state),Qlearn.nearestGhostPos(state))\n",
    "    return currentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearn(Agent):\n",
    "    \n",
    "    def __init__(self, alpha,gamma,epsilon = 1,Qtable = {}):\n",
    "        self.Qtable = Qtable\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.score = 0\n",
    "    \n",
    "    def getQvalue(self,state,action):\n",
    "        pair = (state,action)\n",
    "        return self.Qtable.get(pair,0.0)\n",
    "    \n",
    "    def getAction(self, state):\n",
    "        actions = state.getLegalPacmanActions()\n",
    "        currentState = getState(state)\n",
    "        action = self.getBestAction(currentState,actions)\n",
    "        state2 = state.generatePacmanSuccessor(action)\n",
    "        nextState = getState(state2)\n",
    "        if state.isLose():\n",
    "            reinforcement = -1\n",
    "        else:\n",
    "            reinforcement = state2.getScore() - self.score\n",
    "        self.learn(currentState,nextState,action,actions,reinforcement)\n",
    "        return action\n",
    "        \n",
    "        \n",
    "        def nearestGhostPos(state):\n",
    "            ghostList = state.getGhostPositions()\n",
    "            nearestDistance = self.getNearGhost(state.getPacmanPosition(),ghostList)\n",
    "            return nearestDistance\n",
    "        \n",
    "        def getNearGhost(self,pacman,ghosts):\n",
    "            minDis = float(\"inf\")\n",
    "            minPos = -1\n",
    "            for i in range(len(ghosts)):\n",
    "                distance = manhattanDistance(pacman,ghosts[i])\n",
    "                if distance < minDis:\n",
    "                    minDis = distance\n",
    "                    minPos = i\n",
    "            if minPos > -1:\n",
    "                return ghosts[minPos]\n",
    "            else:\n",
    "                return (-1,-1)\n",
    "        \n",
    "        def getNearestFoodDis(state):\n",
    "            posList = getFoodPos(state.getFood())\n",
    "            posList = posList + state.getCapsules()\n",
    "            minDis = minDis = float(\"inf\")\n",
    "            pacPos = state.getPacmanPosition()\n",
    "            for i in posList:\n",
    "                distance = manhattanDistance(pacPos,i)\n",
    "                if distance < minDis:\n",
    "                    minDis = distance\n",
    "            return minDis\n",
    "            \n",
    "        \n",
    "        def getFoodPos(self,grid):\n",
    "            posList = []\n",
    "            for i in range(len(grid)):\n",
    "                for j in range(len(grid[i])):\n",
    "                    if grid[i][j]:\n",
    "                        posList.append((i,j))\n",
    "        \n",
    "        def getBestAction(self,currentState,actions):\n",
    "            if random.random() < self.epsilon:\n",
    "                return random.choice(actions)\n",
    "            maxValue = flot(\"-inf\")\n",
    "            maxAction = []\n",
    "            for i in actions:\n",
    "                value = self.getQvalue(currentState,i)\n",
    "                if value > maxValue:\n",
    "                    maxValue = value\n",
    "                    maxAction = i\n",
    "            return i\n",
    "        \n",
    "        def learn(self,currentState,nextState,action,actions,reinforcement):\n",
    "            newQ = max([self.getQvalue(nextState,a) for a in actions])\n",
    "            currentQ = self.getQvalue(currentState,action)\n",
    "            self.Qtable[(currentState,action)] = currentQ + self.alpha * (reinforcement + (self.gamma*newQ) - currentQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batata\n",
      "['-q', '--pacman', 'LeftTurnAgent']\n"
     ]
    }
   ],
   "source": [
    "agente = Qlearn()\n",
    "args = readCommand(['-q', '--pacman', 'LeftTurnAgent'])\n",
    "args[\"pacman\"] = agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacman died! Score: 595\n",
      "Average Score: 595.0\n",
      "Scores:        595.0\n",
      "Win Rate:      0/1 (0.00)\n",
      "Record:        Loss\n",
      "[<game.Game object at 0x00000253FCAD38C8>]\n"
     ]
    }
   ],
   "source": [
    "a = runGames(**args)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(a[0].state.isWin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "vector = [0-0,1-0]\n",
    "print(np.linalg.norm(vector))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a33e6643d3d266930a9315102c951dbbb0201b743375bf7e85bc0f4d5308486"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
